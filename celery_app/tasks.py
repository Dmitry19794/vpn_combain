#!/usr/bin/env python3
# vpn/celery_app/tasks.py - –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø

import os
import sys
from celery.schedules import crontab

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import threading
import signal
import atexit
import subprocess
import psycopg2
import time
import traceback as tb
import tempfile
import ipaddress
from psycopg2.extras import RealDictCursor, execute_values
from celery import Celery, Task
from datetime import datetime
from typing import Dict, List, Optional

# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º connection pool –≤ Celery workers
# –ö–∞–∂–¥—ã–π worker —Å–æ–∑–¥–∞–µ—Ç —Å–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
PG_PORT = os.getenv("PGPORT", "5434")
DB_DSN = f"postgresql://brute:securepass123@localhost:{PG_PORT}/brute_system"

VPN_CHECKER_PROCESSES = {}
VPN_CHECKER_LOCK = threading.Lock()

def get_db_connection():
    """–°–æ–∑–¥–∞–µ—Ç –ù–û–í–û–ï —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∫ –ë–î (–±–µ–∑ –ø—É–ª–∞)"""
    try:
        conn = psycopg2.connect(
            DB_DSN,
            connect_timeout=10,
            options='-c statement_timeout=30000'
        )
        conn.autocommit = False
        return conn
    except Exception as e:
        print(f"‚ùå DB connection error: {e}")
        raise

# ============================================
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Celery
# ============================================
app = Celery(
    'tasks',
    broker='redis://localhost:6379/0',
    backend='redis://localhost:6379/1'
)

app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    task_track_started=True,
    broker_connection_retry_on_startup=True,
    worker_prefetch_multiplier=1,  # –í–ê–ñ–ù–û: –Ω–µ –±–µ—Ä–µ–º –∑–∞–¥–∞—á–∏ –∑–∞—Ä–∞–Ω–µ–µ
    task_acks_late=True,
)

CHUNK_SIZE = 1000
CIDR_SPLIT_SIZE = 24

# ============================================
# –õ–û–ì –û–®–ò–ë–û–ö
# ============================================
def save_worker_error(path: str, error: str, tb_text: Optional[str] = None):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—à–∏–±–∫—É –≤ —Ç–∞–±–ª–∏—Ü—É app_errors"""
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO app_errors (method, path, status_code, error, traceback)
            VALUES (%s, %s, %s, %s, %s)
        """, ("CELERY", path, 500, (error or '')[:8000], (tb_text or tb.format_exc())[:16000]))
        conn.commit()
    except Exception as e:
        print(f"‚ùå FAILED TO SAVE CELERY ERROR: {e}")
    finally:
        if conn:
            try:
                conn.close()
            except:
                pass

# ============================================
# –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–¥–∞—á (on_failure)
# ============================================
class MasscanTask(Task):
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        job_id = kwargs.get('job_id') or (args[0] if args else None)
        print(f"‚ùå Task {task_id} failed: {exc}")
        
        if not job_id:
            save_worker_error(path=f"task.on_failure:{task_id}", error=str(exc), tb_text=tb.format_exc())
            return

        conn = None
        try:
            conn = get_db_connection()
            cur = conn.cursor()
            cur.execute("""
                UPDATE scan_jobs
                SET status = 'failed',
                    finished_at = NOW(),
                    process_pid = NULL,
                    control_action = NULL
                WHERE id = %s
            """, (job_id,))
            conn.commit()
        except Exception as e:
            print(f"Failed to update job status in on_failure: {e}")
        finally:
            if conn:
                try:
                    conn.close()
                except:
                    pass

        save_worker_error(path=f"task.on_failure:{task_id}", error=str(exc), tb_text=tb.format_exc())

# ============================================
# –†–ê–ë–û–¢–ê –° –ü–†–û–ö–°–ò
# ============================================
def get_random_proxy(geo: str = None):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –∂–∏–≤–æ–π –ø—Ä–æ–∫—Å–∏ –∏–∑ –ë–î"""
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        if geo:
            cur.execute("""
                SELECT host, port, anonymity, geo
                FROM proxies
                WHERE is_alive = TRUE AND geo = %s
                ORDER BY RANDOM()
                LIMIT 1
            """, (geo,))
        else:
            cur.execute("""
                SELECT host, port, anonymity, geo
                FROM proxies
                WHERE is_alive = TRUE
                ORDER BY RANDOM()
                LIMIT 1
            """)
        
        row = cur.fetchone()
        if row:
            return {
                "host": row[0],
                "port": row[1],
                "anonymity": row[2] if len(row) > 2 else "unknown",
                "geo": row[3] if len(row) > 3 else "unknown"
            }
        return None
        
    except Exception as e:
        print(f"‚ùå get_random_proxy error: {e}")
        return None
    finally:
        if conn:
            try:
                conn.close()
            except:
                pass

def create_proxychains_config(proxy_host: str, proxy_port: int, proxy_type: str = "http") -> str:
    """–°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è proxychains4"""
    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.conf', delete=False) as f:
            config_path = f.name
            f.write(f"""# Proxychains config for nmap
strict_chain
proxy_dns
tcp_read_time_out 30000
tcp_connect_time_out 15000

[ProxyList]
{proxy_type} {proxy_host} {proxy_port}
""")
        
        print(f"üìù Created proxychains config: {proxy_type}://{proxy_host}:{proxy_port}")
        return config_path
        
    except Exception as e:
        print(f"‚ùå Failed to create proxychains config: {e}")
        return None

def run_nmap_via_proxy(target: str, port: int, proxy_info: dict, 
                       output_file: str, timeout: int = 180) -> bool:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç nmap —á–µ—Ä–µ–∑ proxychains"""
    config_path = None
    
    try:
        proxy_host = proxy_info["host"]
        proxy_port = proxy_info["port"]
        proxy_type = "http"
        
        config_path = create_proxychains_config(proxy_host, proxy_port, proxy_type)
        if not config_path:
            return False
        
        cmd = [
            'proxychains4', '-f', config_path, '-q',
            'nmap',
            '-p', str(port),
            '-sT', '-Pn', '--open',
            '-T3',
            '--max-retries', '2',
            '--host-timeout', '60s',
            '--max-rtt-timeout', '2000ms',
            '--initial-rtt-timeout', '500ms',
            '-oG', output_file,
            target
        ]
        
        print(f"üîç Running nmap via proxy {proxy_host}:{proxy_port} for {target}:{port}")
        
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        try:
            stdout, stderr = process.communicate(timeout=timeout)
            returncode = process.returncode
            
            if returncode == 0:
                print(f"‚úÖ Nmap completed for {target}")
                return True
            else:
                print(f"‚ö†Ô∏è Nmap returned code {returncode} for {target}")
                return False
                
        except subprocess.TimeoutExpired:
            print(f"‚è∞ Nmap timeout for {target}")
            try:
                process.kill()
                process.wait(timeout=5)
            except:
                pass
            return False
            
    except Exception as e:
        print(f"‚ùå run_nmap_via_proxy error: {e}")
        return False
        
    finally:
        if config_path and os.path.exists(config_path):
            try:
                os.remove(config_path)
            except:
                pass

def split_cidr_into_blocks(cidr: str, block_size: int = 24) -> List[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç CIDR –Ω–∞ –±–ª–æ–∫–∏"""
    try:
        network = ipaddress.ip_network(cidr, strict=False)
        
        if network.prefixlen >= block_size:
            return [str(network)]
        
        subnets = list(network.subnets(new_prefix=block_size))
        
        if len(subnets) > 1000:
            print(f"‚ö†Ô∏è Too many subnets ({len(subnets)}), taking first 1000")
            subnets = subnets[:1000]
        
        return [str(subnet) for subnet in subnets]
        
    except Exception as e:
        print(f"‚ùå split_cidr error: {e}")
        return [cidr]

def parse_nmap_results(output_file: str, job_id: str, port: int, geo: str, conn) -> int:
    """–ü–∞—Ä—Å–∏—Ç greppable output nmap"""
    total = 0
    if not os.path.exists(output_file):
        return 0

    try:
        with open(output_file, 'r') as f:
            ips = []
            for line in f:
                if 'Host:' in line and 'Ports:' in line:
                    try:
                        parts = line.split()
                        host_idx = parts.index('Host:')
                        ip = parts[host_idx + 1]
                        
                        if '/open/' in line:
                            ips.append(ip)
                            
                    except Exception:
                        continue
                    
                    if len(ips) >= CHUNK_SIZE:
                        try:
                            count = insert_addresses_batch(conn, ips, port, geo, job_id)
                            conn.commit()
                            total += count
                        except Exception as e:
                            try:
                                conn.rollback()
                            except:
                                pass
                            print(f"‚ùå Batch insert error: {e}")
                        ips = []
            
            if ips:
                try:
                    count = insert_addresses_batch(conn, ips, port, geo, job_id)
                    conn.commit()
                    total += count
                except Exception as e:
                    try:
                        conn.rollback()
                    except:
                        pass
                    print(f"‚ùå Final insert error: {e}")
                    
    except Exception as e:
        print(f"‚ùå parse_nmap_results error: {e}")
    
    return total

def insert_addresses_batch(conn, ips: List[str], port: int, geo: str, job_id: str) -> int:
    """–í—Å—Ç–∞–≤–∫–∞ –∞–¥—Ä–µ—Å–æ–≤ - –ë–ï–ó FOREIGN KEY"""
    if not ips:
        return 0

    cur = conn.cursor()
    rows = [(ip, port, geo) for ip in ips]  # –£–ë–†–ê–õ–ò job_id!

    # –£–ë–ò–†–ê–ï–ú job_id –∏–∑ INSERT!
    sql = """
        INSERT INTO scanned_addresses (id, ip, port, geo, is_checked, created_at, updated_at)
        SELECT gen_random_uuid(), data.ip::inet, data.port, data.geo, FALSE, NOW(), NOW()
        FROM (VALUES %s) AS data(ip, port, geo)
        ON CONFLICT (ip, port) DO NOTHING
    """

    try:
        execute_values(cur, sql, rows)
        return len(rows)
    except Exception as e:
        print(f"‚ùå insert_addresses_batch error: {e}")
        return 0

# ============================================
# –û–°–ù–û–í–ù–ê–Ø –ó–ê–î–ê–ß–ê –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–Ø
# ============================================
def test_proxy_for_nmap(proxy_host: str, proxy_port: int) -> bool:
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∫—Å–∏ –¥–ª—è nmap"""
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ñ–∏–≥
        with tempfile.NamedTemporaryFile(mode='w', suffix='.conf', delete=False) as f:
            config_path = f.name
            f.write(f"""strict_chain
                    tcp_connect_time_out 5000
                    [ProxyList]
                    http {proxy_host} {proxy_port}
                    """)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º nmap —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏
        result = subprocess.run(
            ['proxychains4', '-f', config_path, '-q', 
             'nmap', '-p', '443', '-sT', '-Pn', '8.8.8.8'],
            timeout=10,
            capture_output=True,
            text=True
        )
        
        os.remove(config_path)
        
        # –ï—Å–ª–∏ –Ω–∞—à–µ–ª —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ - –ø—Ä–æ–∫—Å–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
        success = 'open' in result.stdout.lower() or result.returncode == 0
        
        if success:
            print(f"‚úÖ Proxy {proxy_host}:{proxy_port} works for nmap")
        else:
            print(f"‚ùå Proxy {proxy_host}:{proxy_port} FAILED for nmap")
        
        return success
        
    except Exception as e:
        print(f"‚ùå Proxy test error: {e}")
        return False

def start_vpn_checker_for_geo(geo: str) -> bool:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç VPN checker –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π GEO –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω —É—Å–ø–µ—à–Ω–æ
    """
    global VPN_CHECKER_PROCESSES
    
    with VPN_CHECKER_LOCK:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å —É–∂–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω
        if geo in VPN_CHECKER_PROCESSES:
            proc = VPN_CHECKER_PROCESSES[geo]
            if proc.poll() is None:  # –ü—Ä–æ—Ü–µ—Å—Å –µ—â–µ –∂–∏–≤
                print(f"‚úÖ VPN Checker for {geo} already running (PID: {proc.pid})")
                return True
            else:
                # –ü—Ä–æ—Ü–µ—Å—Å —É–º–µ—Ä - —É–¥–∞–ª—è–µ–º –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                del VPN_CHECKER_PROCESSES[geo]
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å
        try:
            checker_bin = "/opt/vpn/checker/checker"
            
            if not os.path.exists(checker_bin):
                print(f"‚ùå Checker binary not found: {checker_bin}")
                return False
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º checker —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            proc = subprocess.Popen(
                [checker_bin, f"--geo={geo}"],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                bufsize=1,
                universal_newlines=True
            )
            
            VPN_CHECKER_PROCESSES[geo] = proc
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è —á—Ç–µ–Ω–∏—è –ª–æ–≥–æ–≤
            threading.Thread(
                target=_read_checker_logs,
                args=(proc, geo),
                daemon=True
            ).start()
            
            print(f"üöÄ Started VPN Checker for {geo} (PID: {proc.pid})")
            return True
            
        except Exception as e:
            print(f"‚ùå Failed to start VPN Checker for {geo}: {e}")
            return False

def _read_checker_logs(proc, geo):
    """–ß–∏—Ç–∞–µ—Ç –ª–æ–≥–∏ VPN checker –∏ –≤—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å"""
    try:
        for line in iter(proc.stdout.readline, ''):
            if line:
                print(f"[CHECKER-{geo}] {line.rstrip()}")
    except Exception as e:
        print(f"‚ùå Error reading checker logs for {geo}: {e}")
    finally:
        proc.stdout.close()

def stop_vpn_checker_for_geo(geo: str) -> bool:
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç VPN checker –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π GEO"""
    global VPN_CHECKER_PROCESSES
    
    with VPN_CHECKER_LOCK:
        if geo not in VPN_CHECKER_PROCESSES:
            print(f"‚ö†Ô∏è VPN Checker for {geo} is not running")
            return False
        
        proc = VPN_CHECKER_PROCESSES[geo]
        
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º SIGTERM
            proc.terminate()
            
            # –ñ–¥–µ–º 5 —Å–µ–∫—É–Ω–¥
            try:
                proc.wait(timeout=5)
            except subprocess.TimeoutExpired:
                # –ï—Å–ª–∏ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è - —É–±–∏–≤–∞–µ–º
                proc.kill()
                proc.wait()
            
            del VPN_CHECKER_PROCESSES[geo]
            print(f"üõë Stopped VPN Checker for {geo}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error stopping VPN Checker for {geo}: {e}")
            return False

def get_vpn_checker_status() -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö VPN checker –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"""
    global VPN_CHECKER_PROCESSES
    
    status = {}
    
    with VPN_CHECKER_LOCK:
        for geo, proc in list(VPN_CHECKER_PROCESSES.items()):
            if proc.poll() is None:
                # –ü—Ä–æ—Ü–µ—Å—Å –∂–∏–≤
                status[geo] = {
                    "running": True,
                    "pid": proc.pid
                }
            else:
                # –ü—Ä–æ—Ü–µ—Å—Å —É–º–µ—Ä
                status[geo] = {
                    "running": False,
                    "pid": None
                }
                del VPN_CHECKER_PROCESSES[geo]
    
    return status

# ============================================
# –ú–û–î–ò–§–ò–ö–ê–¶–ò–Ø parse_nmap_results
# ============================================
def parse_nmap_results(output_file: str, job_id: str, port: int, geo: str, conn) -> int:
    """
    –ü–∞—Ä—Å–∏—Ç greppable output nmap
    –ù–û–í–û–ï: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç VPN checker –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Ö–æ—Å—Ç—ã
    """
    total = 0
    if not os.path.exists(output_file):
        return 0

    try:
        with open(output_file, 'r') as f:
            ips = []
            for line in f:
                if 'Host:' in line and 'Ports:' in line:
                    try:
                        parts = line.split()
                        host_idx = parts.index('Host:')
                        ip = parts[host_idx + 1]
                        
                        if '/open/' in line:
                            ips.append(ip)
                            
                    except Exception:
                        continue
                    
                    if len(ips) >= CHUNK_SIZE:
                        try:
                            count = insert_addresses_batch(conn, ips, port, geo, job_id)
                            conn.commit()
                            total += count
                        except Exception as e:
                            try:
                                conn.rollback()
                            except:
                                pass
                            print(f"‚ùå Batch insert error: {e}")
                        ips = []
            
            if ips:
                try:
                    count = insert_addresses_batch(conn, ips, port, geo, job_id)
                    conn.commit()
                    total += count
                except Exception as e:
                    try:
                        conn.rollback()
                    except:
                        pass
                    print(f"‚ùå Final insert error: {e}")
        
        # ‚úÖ –ù–û–í–û–ï: –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Ö–æ—Å—Ç—ã - –∑–∞–ø—É—Å–∫–∞–µ–º VPN checker
        if total > 0:
            print(f"üéØ Found {total} open ports for {geo}, starting VPN checker...")
            start_vpn_checker_for_geo(geo)
                    
    except Exception as e:
        print(f"‚ùå parse_nmap_results error: {e}")
    
    return total

# ============================================
# API ENDPOINTS –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è VPN checker
# ============================================
@app.task(name='tasks.manage_vpn_checker')
def manage_vpn_checker(geo: str, action: str):
    """
    –£–ø—Ä–∞–≤–ª—è–µ—Ç VPN checker –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
    action: 'start', 'stop', 'status'
    """
    if action == 'start':
        return {'status': 'success' if start_vpn_checker_for_geo(geo) else 'failed'}
    
    elif action == 'stop':
        return {'status': 'success' if stop_vpn_checker_for_geo(geo) else 'failed'}
    
    elif action == 'status':
        return get_vpn_checker_status()
    
    else:
        return {'error': f'Invalid action: {action}'}

# ============================================
# Beat schedule –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
# ============================================
app.conf.beat_schedule.update({
    "check-vpn-checkers": {
        "task": "tasks.check_vpn_checker_health",
        "schedule": 60.0,  # –ö–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
    },
})

@app.task(name='tasks.check_vpn_checker_health')
def check_vpn_checker_health():
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ VPN checker –ø—Ä–æ—Ü–µ—Å—Å—ã –∂–∏–≤—ã
    –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ—Ç –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∞–¥—Ä–µ—Å–∞ –Ω–æ checker –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
    """
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ GEO —Å –Ω–µ–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –∞–¥—Ä–µ—Å–∞–º–∏
        cur.execute("""
            SELECT geo, COUNT(*) as cnt
            FROM scanned_addresses
            WHERE is_checked = FALSE
            GROUP BY geo
            HAVING COUNT(*) > 0
        """)
        
        rows = cur.fetchall()
        
        for row in rows:
            geo = row[0]
            count = row[1]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ checker –∑–∞–ø—É—â–µ–Ω
            status = get_vpn_checker_status()
            
            if geo not in status or not status[geo].get('running'):
                print(f"‚ö†Ô∏è {geo} has {count} unchecked addresses but checker is not running")
                print(f"üöÄ Auto-starting VPN checker for {geo}")
                start_vpn_checker_for_geo(geo)
        
        conn.close()
        
    except Exception as e:
        print(f"‚ùå check_vpn_checker_health error: {e}")
        if conn:
            try:
                conn.close()
            except:
                pass

# ============================================
# Graceful shutdown –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ Celery
# ============================================
def shutdown_all_checkers():
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ VPN checker –ø—Ä–æ—Ü–µ—Å—Å—ã"""
    global VPN_CHECKER_PROCESSES
    
    print("üõë Shutting down all VPN checkers...")
    
    with VPN_CHECKER_LOCK:
        for geo in list(VPN_CHECKER_PROCESSES.keys()):
            stop_vpn_checker_for_geo(geo)
    
    print("‚úÖ All VPN checkers stopped")

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤
import atexit
atexit.register(shutdown_all_checkers)

@app.task(bind=True, name='tasks.run_masscan', base=MasscanTask)
def run_masscan(self, job_id: str, cidr: str, port: int, geo: str):
    """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ (—Å fallback –Ω–∞ –ø—Ä—è–º–æ–π nmap)"""
    print(f"üîç Starting distributed scan: {cidr}:{port} (Job={job_id}, GEO={geo})")
    
    start_time = time.time()
    total_results = 0
    conn = None
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –ø–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ running
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("""
            UPDATE scan_jobs
            SET status = 'running',
                started_at = NOW(),
                assigned_to = %s,
                progress_percent = 0,
                control_action = NULL
            WHERE id = %s
        """, (self.request.id, job_id))
        conn.commit()
        conn.close()
        conn = None

        # –†–∞–∑–±–∏–≤–∞–µ–º CIDR –Ω–∞ –±–ª–æ–∫–∏
        blocks = split_cidr_into_blocks(cidr, CIDR_SPLIT_SIZE)
        total_blocks = len(blocks)
        print(f"üìä Split {cidr} into {total_blocks} blocks (/{CIDR_SPLIT_SIZE})")
        
        if total_blocks > 100:
            print(f"‚ö†Ô∏è Too many blocks ({total_blocks}), limiting to 100")
            blocks = blocks[:100]
            total_blocks = 100

        # –°–∫–∞–Ω–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –±–ª–æ–∫
        for i, block in enumerate(blocks):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º control actions
            try:
                conn = get_db_connection()
                cur = conn.cursor()
                cur.execute("SELECT control_action FROM scan_jobs WHERE id = %s", (job_id,))
                row = cur.fetchone()
                ctrl = row[0] if row else None
                conn.close()
                conn = None
            except Exception as e:
                print(f"‚ö†Ô∏è Error checking control: {e}")
                ctrl = None
                if conn:
                    try:
                        conn.close()
                    except:
                        pass
                    conn = None
            
            if ctrl == 'stop':
                print(f"üõë Stopping job {job_id}")
                break

            # === –ü–û–õ–£–ß–ï–ù–ò–ï –ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ö–°–ò ===
            proxy_info = None
            for attempt in range(5):  # –ü—Ä–æ–±—É–µ–º –¥–æ 5 –ø—Ä–æ–∫—Å–∏
                candidate = get_random_proxy(geo)
                if not candidate:
                    print(f"‚ö†Ô∏è No more proxies for GEO={geo} (attempt {attempt+1}/5)")
                    break

                host, port_candidate = candidate["host"], candidate["port"]
                print(f"üß™ Testing proxy {host}:{port_candidate} (attempt {attempt+1}/5)...")
                
                if test_proxy_for_nmap(host, port_candidate):
                    proxy_info = candidate
                    print(f"‚úÖ Selected working proxy: {host}:{port_candidate}")
                    break
                else:
                    # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –º—ë—Ä—Ç–≤—ã–π
                    try:
                        db_conn = get_db_connection()
                        db_cur = db_conn.cursor()
                        db_cur.execute("""
                            UPDATE proxies 
                            SET is_alive = FALSE, updated_at = NOW()
                            WHERE host = %s AND port = %s
                        """, (host, port_candidate))
                        db_conn.commit()
                        db_conn.close()
                        print(f"üíÄ Marked proxy {host}:{port_candidate} as dead")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Failed to mark proxy dead: {e}")

            # === –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï: –ø—Ä–æ–∫—Å–∏ –∏–ª–∏ –ø—Ä—è–º–æ–µ ===
            output_file = f"/tmp/nmap_{job_id}_{i}.txt"
            success = False

            if proxy_info:
                # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏
                print(f"üîç Scanning {block}:{port} via proxy {proxy_info['host']}:{proxy_info['port']}")
                try:
                    success = run_nmap_via_proxy(
                        target=block,
                        port=port,
                        proxy_info=proxy_info,
                        output_file=output_file,
                        timeout=180
                    )
                except Exception as e:
                    print(f"‚ùå Nmap via proxy error for {block}: {e}")
                    success = False
            else:
                # üö´ –ù–µ—Ç —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏ ‚Äî —Å–∫–∞–Ω–∏—Ä—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
                print(f"üåê No working proxy ‚Äî falling back to DIRECT nmap scan for {block}:{port}")
                try:
                    cmd = [
                        'nmap',
                        '-p', str(port),
                        '-sT', '-Pn', '--open',
                        '-T3',
                        '--max-retries', '2',
                        '--host-timeout', '60s',
                        '--max-rtt-timeout', '2000ms',
                        '--initial-rtt-timeout', '500ms',
                        '-oG', output_file,
                        block
                    ]
                    print(f"‚ñ∂Ô∏è Running: {' '.join(cmd)}")
                    
                    process = subprocess.Popen(
                        cmd,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True
                    )
                    stdout, stderr = process.communicate(timeout=180)
                    returncode = process.returncode
                    success = (returncode == 0)
                    
                    if success:
                        print(f"‚úÖ Direct nmap completed for {block}")
                    else:
                        print(f"‚ö†Ô∏è Direct nmap failed (code {returncode}) for {block}")
                        if stderr.strip():
                            print(f"   STDERR: {stderr[:200]}...")
                
                except subprocess.TimeoutExpired:
                    print(f"‚è∞ Direct nmap timeout for {block}")
                    try:
                        process.kill()
                        process.wait(timeout=5)
                    except:
                        pass
                    success = False
                except Exception as e:
                    print(f"‚ùå Direct nmap error: {e}")
                    success = False

            # === –û–ë–†–ê–ë–û–¢–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
            if success and os.path.exists(output_file):
                try:
                    conn = get_db_connection()
                    count = parse_nmap_results(output_file, job_id, port, geo, conn)
                    conn.commit()
                    total_results += count
                    print(f"‚úÖ Block {i+1}/{total_blocks}: found {count} hosts")
                except Exception as e:
                    print(f"‚ùå Parse error for block {i}: {e}")
                    if conn:
                        try:
                            conn.rollback()
                        except:
                            pass
                finally:
                    if conn:
                        try:
                            conn.close()
                        except:
                            pass
                    conn = None
            else:
                print(f"‚ö†Ô∏è Block {i+1}/{total_blocks}: scan failed or no output")

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                if os.path.exists(output_file):
                    os.remove(output_file)
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to remove {output_file}: {e}")

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress = ((i + 1) / total_blocks) * 100
            try:
                conn = get_db_connection()
                cur = conn.cursor()
                cur.execute("""
                    UPDATE scan_jobs
                    SET progress_percent = %s,
                        result_count = %s
                    WHERE id = %s
                """, (progress, total_results, job_id))
                conn.commit()
                conn.close()
                conn = None
            except Exception as e:
                print(f"‚ö†Ô∏è Progress update error: {e}")
                if conn:
                    try:
                        conn.close()
                    except:
                        pass
                    conn = None

            # –û–±–Ω–æ–≤–ª—è–µ–º Celery state
            try:
                elapsed = time.time() - start_time
                self.update_state(
                    state='PROGRESS',
                    meta={
                        'job_id': job_id,
                        'cidr': cidr,
                        'progress': progress,
                        'blocks_done': i + 1,
                        'blocks_total': total_blocks,
                        'results': total_results,
                        'elapsed': int(elapsed)
                    }
                )
            except:
                pass

        # === –§–ò–ù–ê–õ–¨–ù–û–ï –û–ë–ù–û–í–õ–ï–ù–ò–ï ===
        elapsed = time.time() - start_time
        try:
            conn = get_db_connection()
            cur = conn.cursor()
            cur.execute("""
                UPDATE scan_jobs
                SET status = 'completed',
                    finished_at = NOW(),
                    result_count = %s,
                    progress_percent = 100,
                    process_pid = NULL,
                    control_action = NULL
                WHERE id = %s
            """, (total_results, job_id))
            conn.commit()
        except Exception as e:
            print(f"‚ùå Final update error: {e}")
        finally:
            if conn:
                try:
                    conn.close()
                except:
                    pass

        print(f"‚úÖ Job {job_id} completed: {total_results} hosts in {int(elapsed)}s")
        return {
            'status': 'completed',
            'job_id': job_id,
            'cidr': cidr,
            'port': port,
            'geo': geo,
            'result_count': total_results,
            'elapsed_seconds': int(elapsed),
            'blocks_scanned': total_blocks
        }

    except Exception as e:
        print(f"‚ùå Fatal error in run_masscan: {e}")
        import traceback
        traceback.print_exc()

        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ failed
        try:
            conn = get_db_connection()
            cur = conn.cursor()
            cur.execute("""
                UPDATE scan_jobs
                SET status = 'failed',
                    finished_at = NOW(),
                    result_count = %s,
                    process_pid = NULL,
                    control_action = NULL
                WHERE id = %s
            """, (total_results, job_id))
            conn.commit()
        except:
            pass
        finally:
            if conn:
                try:
                    conn.close()
                except:
                    pass

        raise

# ============================================
# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏
# ============================================
@app.task(name='tasks.control_job')
def control_job(job_id: str, action: str):
    if action not in ['pause', 'resume', 'stop']:
        return {'error': f'Invalid action: {action}'}

    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("""
            UPDATE scan_jobs
            SET control_action = %s,
                control_updated_at = NOW()
            WHERE id = %s
            RETURNING status
        """, (action, job_id))
        row = cur.fetchone()
        if not row:
            try:
                conn.rollback()
            except:
                pass
            return {'error': 'Job not found'}
        conn.commit()
        print(f"üéõÔ∏è Job {job_id}: action={action}")
        result = {
            'status': 'success',
            'job_id': job_id,
            'action': action,
            'current_status': row.get('status') if isinstance(row, dict) else row[0]
        }
        return result
    except Exception as e:
        print(f"‚ùå Error controlling job: {e}")
        try:
            if conn:
                conn.rollback()
        except:
            pass
        save_worker_error(path=f"control_job:{job_id}", error=str(e), tb_text=tb.format_exc())
        return {'error': str(e)}
    finally:
        if conn:
            try:
                conn.close()
            except:
                pass

# ============================================
# –ê–í–¢–û–ó–ê–ü–£–°–ö PENDING - –ò–°–ü–†–ê–í–õ–ï–ù–û
# ============================================
@app.task(name='tasks.process_pending_scans')
def process_pending_scans(geo: str = 'US', limit: int = 10):
    """–ë–µ—Ä—ë–º pending –∑–∞–¥–∞—á–∏ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º"""
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        cur.execute("""
            SELECT j.id, s.cidr, p.port, s.geo
            FROM scan_jobs j
            JOIN scan_subnets s ON j.subnet_id = s.id
            JOIN scan_ports p ON j.port_id = p.id
            WHERE j.status = 'pending' AND s.geo = %s
            ORDER BY j.created_at ASC
            LIMIT %s
            FOR UPDATE SKIP LOCKED
        """, (geo, limit))
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø—Ä–æ–≤–µ—Ä—è–µ–º rowcount –î–û fetchall
        if cur.rowcount == 0:
            conn.commit()
            return None
            
        jobs = cur.fetchall()
        
        if not jobs:
            conn.commit()
            return None

        launched = []
        for job in jobs:
            jid = str(job[0])
            cidr = job[1]
            p = job[2]
            g = job[3]
            cur.execute("UPDATE scan_jobs SET status='queued' WHERE id=%s", (jid,))
            launched.append(jid)
            run_masscan.delay(jid, cidr, p, g)

        conn.commit()
        return {'status': 'launched', 'count': len(launched)}
        
    except Exception as e:
        print(f"‚ùå process_pending_scans error: {e}")
        try:
            if conn:
                conn.rollback()
        except:
            pass
        return None
    finally:
        if conn:
            try:
                conn.close()
            except:
                pass

# ============================================
# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
# ============================================
@app.task(name='tasks.cleanup_old_data')
def cleanup_old_data(days: int = 7):
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("""
            DELETE FROM scan_jobs
            WHERE status IN ('completed', 'stopped', 'failed')
            AND finished_at < NOW() - INTERVAL '%s days'
        """, (days,))
        deleted_jobs = cur.rowcount

        cur.execute("""
            DELETE FROM scanned_addresses
            WHERE is_checked = TRUE 
            AND updated_at < NOW() - INTERVAL '%s days'
        """, (days,))
        deleted_addrs = cur.rowcount

        conn.commit()
        print(f"üßπ Cleaned: {deleted_jobs} jobs, {deleted_addrs} addresses")
        return {'status': 'success', 'deleted_jobs': deleted_jobs, 'deleted_addresses': deleted_addrs}
    except Exception as e:
        print(f"‚ùå Cleanup error: {e}")
        try:
            if conn:
                conn.rollback()
        except:
            pass
        save_worker_error(path=f"cleanup_old_data:{days}", error=str(e), tb_text=tb.format_exc())
        raise
    finally:
        if conn:
            try:
                conn.close()
            except:
                pass

# ============================================
# Beat schedule
# ============================================
app.conf.beat_schedule = {
    "auto-start-pending-us": {
        "task": "tasks.process_pending_scans",
        "schedule": 15.0,
        "args": ("US", 10),
    },
}
